"""
SenseVoice API ç®€åŒ–ç‰ˆ - ä¸“ä¸º AI-EVA Demo ä¼˜åŒ–
æ”¯æŒæµè§ˆå™¨éŸ³é¢‘æµä¸Šä¼ å’Œå®æ—¶è¯­éŸ³è¯†åˆ«
"""
import os
import asyncio
import logging
from typing import Optional, List
from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import torch
import torchaudio
import numpy as np
from io import BytesIO
import tempfile
from pathlib import Path

# å¯¼å…¥ SenseVoice ç›¸å…³æ¨¡å—
try:
    from SenseVoice.model import SenseVoiceSmall
    from funasr.utils.postprocess_utils import rich_transcription_postprocess
    SENSEVOICE_AVAILABLE = True
except ImportError:
    SENSEVOICE_AVAILABLE = False
    print("âš ï¸  SenseVoice æ¨¡å—æœªæ‰¾åˆ°ï¼Œè¯­éŸ³è¯†åˆ«åŠŸèƒ½å°†ä¸å¯ç”¨")

from config import config
from utils.logger import get_logger

# åˆå§‹åŒ–æ—¥å¿—
logger = get_logger("sensevoice")

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="SenseVoice API",
    description="AI-EVA Demo è¯­éŸ³è¯†åˆ«æœåŠ¡",
    version="1.0.0"
)

# æ·»åŠ  CORS æ”¯æŒ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡
model = None
device = None

# ç›®æ ‡é‡‡æ ·ç‡
TARGET_FS = 16000

class SenseVoiceAPI:
    """SenseVoice API ç®¡ç†å™¨"""
    
    def __init__(self):
        self.model = None
        self.device = None
        self.is_loaded = False
        
    async def load_model(self):
        """å¼‚æ­¥åŠ è½½æ¨¡å‹"""
        if not SENSEVOICE_AVAILABLE:
            raise HTTPException(
                status_code=500, 
                detail="SenseVoice æ¨¡å—æœªå®‰è£…ï¼Œè¯·æ£€æŸ¥ä¾èµ–"
            )
        
        try:
            logger.info("æ­£åœ¨åŠ è½½ SenseVoice æ¨¡å‹...")
            
            # è‡ªåŠ¨æ£€æµ‹å¯ç”¨è®¾å¤‡
            import torch
            if config.USE_GPU and torch.cuda.is_available():
                self.device = config.SENSEVOICE_DEVICE
                logger.info(f"âœ… ä½¿ç”¨ GPU è®¾å¤‡: {self.device}")
            else:
                self.device = "cpu"
                if config.USE_GPU and not torch.cuda.is_available():
                    logger.warning("âš ï¸  CUDA ä¸å¯ç”¨ï¼Œé™çº§åˆ° CPU")
                else:
                    logger.info(f"ä½¿ç”¨ CPU è®¾å¤‡")
            
            # åŠ è½½æ¨¡å‹
            model_dir = "iic/SenseVoiceSmall"
            self.model, kwargs = SenseVoiceSmall.from_pretrained(
                model=model_dir, 
                device=self.device
            )
            self.model.eval()
            
            self.is_loaded = True
            logger.info("âœ… SenseVoice æ¨¡å‹åŠ è½½å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise HTTPException(
                status_code=500,
                detail=f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"
            )
    
    async def transcribe_audio(self, audio_data: bytes, language: str = "auto") -> str:
        """è½¬å½•éŸ³é¢‘ä¸ºæ–‡æœ¬"""
        if not self.is_loaded:
            await self.load_model()
        
        try:
            # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸ºéŸ³é¢‘å¼ é‡
            audio_io = BytesIO(audio_data)
            waveform, sample_rate = torchaudio.load(audio_io)
            
            # è½¬æ¢ä¸ºå•å£°é“
            if waveform.shape[0] > 1:
                waveform = waveform.mean(0, keepdim=True)
            
            # é‡é‡‡æ ·åˆ°ç›®æ ‡é‡‡æ ·ç‡
            if sample_rate != TARGET_FS:
                resampler = torchaudio.transforms.Resample(
                    orig_freq=sample_rate, 
                    new_freq=TARGET_FS
                )
                waveform = resampler(waveform)
            
            # è½¬æ¢ä¸º numpy æ•°ç»„
            audio_array = waveform.squeeze().numpy()
            
            # æ¨ç†
            result = self.model.inference(
                data_in=[audio_array],
                language=language,
                use_itn=False,
                ban_emo_unk=False,
                key=["audio"],
                fs=TARGET_FS
            )
            
            if result and len(result) > 0 and len(result[0]) > 0:
                text = result[0][0]["text"]
                # åå¤„ç†
                text = rich_transcription_postprocess(text)
                return text.strip()
            else:
                return ""
                
        except Exception as e:
            logger.error(f"è½¬å½•å¤±è´¥: {e}")
            raise HTTPException(
                status_code=500,
                detail=f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}"
            )

# åˆ›å»º API å®ä¾‹
sensevoice_api = SenseVoiceAPI()

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–"""
    logger.info("ğŸš€ SenseVoice API å¯åŠ¨ä¸­...")
    
    # é¢„åŠ è½½æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
    if config.USE_GPU:
        try:
            await sensevoice_api.load_model()
            logger.info("âœ… æ¨¡å‹é¢„åŠ è½½å®Œæˆ")
        except Exception as e:
            logger.warning(f"æ¨¡å‹é¢„åŠ è½½å¤±è´¥ï¼Œå°†åœ¨é¦–æ¬¡è¯·æ±‚æ—¶åŠ è½½: {e}")

@app.get("/")
async def root():
    """æ ¹è·¯å¾„ - æœåŠ¡çŠ¶æ€"""
    return {
        "service": "SenseVoice API",
        "version": "1.0.0",
        "status": "running",
        "model_loaded": sensevoice_api.is_loaded,
        "device": sensevoice_api.device if sensevoice_api.device else "unknown"
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "model_available": SENSEVOICE_AVAILABLE,
        "model_loaded": sensevoice_api.is_loaded
    }

@app.post("/api/v1/asr")
async def speech_to_text(
    file: UploadFile = File(..., description="éŸ³é¢‘æ–‡ä»¶ (wav/mp3/m4a)"),
    language: str = Form(default="auto", description="è¯­è¨€ä»£ç  (auto/zh/en/yue/ja/ko)")
):
    """
    è¯­éŸ³è½¬æ–‡å­— API
    
    Args:
        file: éŸ³é¢‘æ–‡ä»¶
        language: è¯­è¨€ä»£ç 
        
    Returns:
        è¯†åˆ«ç»“æœ
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not file.content_type.startswith('audio/'):
            raise HTTPException(
                status_code=400,
                detail="æ–‡ä»¶ç±»å‹é”™è¯¯ï¼Œè¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"
            )
        
        # è¯»å–éŸ³é¢‘æ•°æ®
        audio_data = await file.read()
        if len(audio_data) == 0:
            raise HTTPException(
                status_code=400,
                detail="éŸ³é¢‘æ–‡ä»¶ä¸ºç©º"
            )
        
        logger.info(f"æ”¶åˆ°éŸ³é¢‘æ–‡ä»¶: {file.filename}, å¤§å°: {len(audio_data)} bytes")
        
        # è½¬å½•éŸ³é¢‘
        text = await sensevoice_api.transcribe_audio(audio_data, language)
        
        logger.info(f"è¯†åˆ«ç»“æœ: {text}")
        
        return {
            "success": True,
            "text": text,
            "language": language,
            "confidence": 1.0  # SenseVoice ä¸æä¾›ç½®ä¿¡åº¦
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"API é”™è¯¯: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"å¤„ç†å¤±è´¥: {str(e)}"
        )

@app.post("/api/v1/asr/batch")
async def batch_speech_to_text(
    files: List[UploadFile] = File(..., description="éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨"),
    language: str = Form(default="auto", description="è¯­è¨€ä»£ç ")
):
    """
    æ‰¹é‡è¯­éŸ³è½¬æ–‡å­— API
    
    Args:
        files: éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨
        language: è¯­è¨€ä»£ç 
        
    Returns:
        æ‰¹é‡è¯†åˆ«ç»“æœ
    """
    try:
        results = []
        
        for i, file in enumerate(files):
            try:
                audio_data = await file.read()
                text = await sensevoice_api.transcribe_audio(audio_data, language)
                
                results.append({
                    "index": i,
                    "filename": file.filename,
                    "text": text,
                    "success": True
                })
                
            except Exception as e:
                results.append({
                    "index": i,
                    "filename": file.filename,
                    "text": "",
                    "success": False,
                    "error": str(e)
                })
        
        return {
            "success": True,
            "results": results,
            "total": len(files)
        }
        
    except Exception as e:
        logger.error(f"æ‰¹é‡å¤„ç†é”™è¯¯: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}"
        )

@app.get("/api/v1/models")
async def get_models():
    """è·å–å¯ç”¨æ¨¡å‹ä¿¡æ¯"""
    return {
        "available": SENSEVOICE_AVAILABLE,
        "loaded": sensevoice_api.is_loaded,
        "device": sensevoice_api.device,
        "supported_languages": ["auto", "zh", "en", "yue", "ja", "ko"],
        "supported_formats": ["wav", "mp3", "m4a", "flac"]
    }

if __name__ == "__main__":
    import uvicorn
    
    logger.info(f"å¯åŠ¨ SenseVoice API æœåŠ¡...")
    logger.info(f"æœåŠ¡åœ°å€: http://{config.SENSEVOICE_HOST}:{config.SENSEVOICE_PORT}")
    
    uvicorn.run(
        app,
        host=config.SENSEVOICE_HOST,
        port=config.SENSEVOICE_PORT,
        log_level=config.LOG_LEVEL.lower()
    )
