# Set the device with environment, default is cuda:0
# export SENSEVOICE_DEVICE=cuda:1

import os
import re
import sys
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ° Python è·¯å¾„ï¼Œç¡®ä¿å¯ä»¥å¯¼å…¥ model
current_dir = Path(__file__).parent
if str(current_dir) not in sys.path:
    sys.path.insert(0, str(current_dir))

from fastapi import FastAPI, File, Form, UploadFile
from fastapi.responses import HTMLResponse
from fastapi.middleware.cors import CORSMiddleware
from typing_extensions import Annotated
from typing import List
from enum import Enum
import torch
import torchaudio
import soundfile as sf
import numpy as np
from model import SenseVoiceSmall
from funasr.utils.postprocess_utils import rich_transcription_postprocess
from io import BytesIO

TARGET_FS = 16000


class Language(str, Enum):
    auto = "auto"
    zh = "zh"
    en = "en"
    yue = "yue"
    ja = "ja"
    ko = "ko"
    nospeech = "nospeech"


model_dir = "iic/SenseVoiceSmall"

# è‡ªåŠ¨æ£€æµ‹å¯ç”¨è®¾å¤‡
import torch
if torch.cuda.is_available():
    device = os.getenv("SENSEVOICE_DEVICE", "cuda:0")
    print(f"âœ… ä½¿ç”¨ GPU è®¾å¤‡: {device}")
else:
    device = "cpu"
    print(f"âš ï¸  CUDA ä¸å¯ç”¨ï¼Œä½¿ç”¨ CPU è®¾å¤‡")

try:
    print(f"ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹: {model_dir}")
    print(f"ğŸ“‚ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    m, kwargs = SenseVoiceSmall.from_pretrained(model=model_dir, device=device)
    m.eval()
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    import traceback
    print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
    traceback.print_exc()
    raise

regex = r"<\|.*\|>"

app = FastAPI()

# æ·»åŠ  CORS ä¸­é—´ä»¶ï¼Œå…è®¸è·¨åŸŸè¯·æ±‚
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æºï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®æŒ‡å®šå…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰HTTPæ–¹æ³•
    allow_headers=["*"],  # å…è®¸æ‰€æœ‰è¯·æ±‚å¤´
)


@app.get("/", response_class=HTMLResponse)
async def root():
    return """
    <!DOCTYPE html>
    <html>
        <head>
            <meta charset=utf-8>
            <title>Api information</title>
        </head>
        <body>
            <a href='./docs'>Documents of API</a>
        </body>
    </html>
    """


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    try:
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
        model_loaded = m is not None and hasattr(m, 'eval')
        return {
            "status": "healthy",
            "service": "SenseVoice",
            "model_loaded": model_loaded,
            "device": device
        }
    except Exception as e:
        return {
            "status": "error",
            "service": "SenseVoice",
            "error": str(e)
        }


@app.post("/api/v1/asr")
async def turn_audio_to_text(
    files: Annotated[List[UploadFile], File(description="wav or mp3 audios in 16KHz")] = None,
    file: UploadFile = File(None, description="å•ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼ˆå…¼å®¹å‰ç«¯è°ƒç”¨ï¼‰"),
    keys: Annotated[str, Form(description="name of each audio joined with comma")] = None,
    lang: Annotated[str, Form(description="language of audio content")] = None,
    language: Annotated[str, Form(description="language of audio content (å…¼å®¹å‰ç«¯)")] = None,
):
    # å…¼å®¹å‰ç«¯è°ƒç”¨ï¼šæ”¯æŒå•ä¸ª file æˆ–å¤šä¸ª files
    if file is not None:
        files = [file]
    
    if files is None or len(files) == 0:
        return {"result": [], "text": "", "error": "æœªæä¾›éŸ³é¢‘æ–‡ä»¶"}
    
    # å¤„ç†è¯­è¨€å‚æ•°ï¼šå…¼å®¹ lang å’Œ language
    if lang is None:
        if language is not None:
            lang = language
        else:
            lang = "auto"
    
    if lang == "" or lang is None:
        lang = "auto"
    
    # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸º Language æšä¸¾ï¼ˆå¦‚æœå¯èƒ½ï¼‰
    try:
        lang_enum = Language(lang)
    except ValueError:
        lang_enum = Language.auto
    
    audios = []
    for file_item in files:
        file_io = BytesIO(await file_item.read())
        audio_fs = None
        data_or_path_or_list = None
        
        # ä¼˜å…ˆä½¿ç”¨ soundfile åŠ è½½éŸ³é¢‘ï¼ˆé¿å… torchcodec ä¾èµ–ï¼‰
        try:
            file_io.seek(0)
            audio_data, audio_fs = sf.read(file_io, dtype='float32')
            
            # è½¬æ¢ä¸º torch tensor
            if len(audio_data.shape) == 1:
                # å•å£°é“
                data_or_path_or_list = torch.from_numpy(audio_data)
            else:
                # å¤šå£°é“ï¼Œå–å¹³å‡å€¼
                data_or_path_or_list = torch.from_numpy(audio_data.mean(axis=1))
            
        except Exception as e:
            # å¦‚æœ soundfile å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ torchaudioï¼ˆå¯èƒ½éœ€è¦ torchcodecï¼‰
            try:
                file_io.seek(0)
                data_or_path_or_list, audio_fs = torchaudio.load(file_io)
                # å¦‚æœæ˜¯å¤šå£°é“ï¼Œå–å¹³å‡å€¼
                if len(data_or_path_or_list.shape) > 1:
                    data_or_path_or_list = data_or_path_or_list.mean(0)
            except Exception as e2:
                return {
                    "result": [],
                    "text": "",
                    "error": f"éŸ³é¢‘åŠ è½½å¤±è´¥: soundfileé”™è¯¯={str(e)}, torchaudioé”™è¯¯={str(e2)}"
                }
        
        # é‡é‡‡æ ·åˆ°ç›®æ ‡é‡‡æ ·ç‡
        if audio_fs and audio_fs != TARGET_FS:
            data_tensor = data_or_path_or_list.unsqueeze(0)  # æ·»åŠ é€šé“ç»´åº¦ [1, samples]
            resampler = torchaudio.transforms.Resample(orig_freq=audio_fs, new_freq=TARGET_FS)
            data_or_path_or_list = resampler(data_tensor).squeeze(0)  # ç§»é™¤é€šé“ç»´åº¦
        
        audios.append(data_or_path_or_list)

    if not keys:
        key = [f.filename or "audio.wav" for f in files]
    else:
        key = keys.split(",")

    res = m.inference(
        data_in=audios,
        language=lang_enum,  # "zh", "en", "yue", "ja", "ko", "nospeech"
        use_itn=False,
        ban_emo_unk=False,
        key=key,
        fs=TARGET_FS,
        **kwargs,
    )
    
    if len(res) == 0 or len(res[0]) == 0:
        return {"result": [], "text": ""}
    
    # å¤„ç†ç»“æœ
    for it in res[0]:
        it["raw_text"] = it["text"]
        it["clean_text"] = re.sub(regex, "", it["text"], 0, re.MULTILINE)
        it["text"] = rich_transcription_postprocess(it["text"])
    
    # å…¼å®¹å‰ç«¯è°ƒç”¨ï¼šè¿”å›å•ä¸ªæ–‡æœ¬ç»“æœ
    first_result_text = res[0][0]["text"] if len(res[0]) > 0 else ""
    
    # è¿”å›æ ¼å¼ï¼šåŒæ—¶æ”¯æŒæ‰¹é‡æ ¼å¼å’Œå•ä¸ªæ–‡æœ¬æ ¼å¼
    return {
        "result": res[0],
        "text": first_result_text,  # å‰ç«¯æœŸæœ›çš„æ ¼å¼
        "success": True
    }


if __name__ == "__main__":
    import uvicorn
    
    try:
        print(f"ğŸš€ å¯åŠ¨ SenseVoice æœåŠ¡...")
        print(f"ğŸ“¡ ç›‘å¬åœ°å€: 0.0.0.0:50000")
        uvicorn.run(app, host="0.0.0.0", port=50000)
    except Exception as e:
        print(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        input("æŒ‰ Enter é”®é€€å‡º...")
